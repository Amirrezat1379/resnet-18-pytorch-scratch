{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting RESNET-18 device as mps\n"
     ]
    }
   ],
   "source": [
    "from EEResnet18 import ResNet, ResidualBlock, data_loader\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends\n",
    "import torch.backends.mps\n",
    "import torch.mps\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "50000\n",
      "Files already downloaded and verified\n",
      "Setting TEST device as mps\n"
     ]
    }
   ],
   "source": [
    "train_loader, valid_loader = data_loader(data_dir='./data',\n",
    "                                         batch_size=64, data_model=\"cifar10\")\n",
    "\n",
    "test_loader = data_loader(data_dir='./data',\n",
    "                              batch_size=1,\n",
    "                              test=True, data_model=\"cifar10\")\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "elif torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "print(f\"Setting TEST device as {device}\")\n",
    "\n",
    "device = torch.device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlyExitLayers = [1, 2, 3, 4]\n",
    "earlyExitNumber = len(earlyExitLayers)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def calculate_loss(pred, target):\n",
    "    cum_loss = []\n",
    "    accuracy = []\n",
    "    for i in range(earlyExitNumber + 1):\n",
    "        cum_loss.append(criterion(pred[i], target))\n",
    "        _, predicted = torch.max(pred[i].data, 1)\n",
    "        accuracy.append((predicted == target).sum().item())\n",
    "\n",
    "    return cum_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 ================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 6/704 [00:09<17:47,  1.53s/it, avg_loss=0, avg_accuracy=12.7]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 63\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m images, labels, outputs\n\u001b[1;32m     62\u001b[0m torch\u001b[38;5;241m.\u001b[39mmps\u001b[38;5;241m.\u001b[39mempty_cache() \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mbackends\u001b[38;5;241m.\u001b[39mmps\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n\u001b[0;32m---> 63\u001b[0m \u001b[43mgc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m==\u001b[39m total_step \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m     66\u001b[0m     bar_step\u001b[38;5;241m.\u001b[39mset_postfix({\n\u001b[1;32m     67\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavg_loss\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(total_loss) \u001b[38;5;241m/\u001b[39m (i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m     68\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavg_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m: (\u001b[38;5;28msum\u001b[39m(layers_accuracy)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m3\u001b[39m) \u001b[38;5;241m/\u001b[39m (i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m     69\u001b[0m                 \u001b[38;5;66;03m# 'max_abs_gradient': np.max(abs(model.weight.grad))\u001b[39;00m\n\u001b[1;32m     70\u001b[0m             })\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_classes = 10\n",
    "num_epochs = 10\n",
    "# batch_size = 16\n",
    "learning_rate = 0.01\n",
    "\n",
    "model = ResNet().to(device)\n",
    "# model.requires_grad_ = True\n",
    "# model = ResNet()\n",
    "model.make_backbone(ResidualBlock, [2, 2, 2, 2], earlyExitLayers, num_classes)\n",
    "\n",
    "# Loss and optimizer\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay = 0.001, momentum = 0.9)  \n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay = 0.001)  \n",
    "\n",
    "# Train the model\n",
    "# total_step = len(train_loader)\n",
    "# print(len(train_loader))\n",
    "import gc\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch+1} ================\")\n",
    "    # n_batch = (n_sample - 1) // batch_size + 1\n",
    "    model.train()\n",
    "    total_sample = 0\n",
    "    total_loss = total_accuracy = 0\n",
    "    layers_accuracy = []\n",
    "    losses = []\n",
    "    [layers_accuracy.append(0) for i in range(earlyExitNumber + 1)]\n",
    "    # for j in range(1):\n",
    "    with tqdm(total=total_step) as bar_step:\n",
    "        for i, (images, labels) in enumerate(train_loader): \n",
    "            # print(i) \n",
    "            # Move tensors to the configured device\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            # print(outputs[-1].size())\n",
    "            # _, predicted = torch.max(outputs.data, 1)\n",
    "            # total_accuracy += (predicted == labels).sum().item()\n",
    "            # loss = criterion(outputs[-1], labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss, accuracy = calculate_loss(outputs, labels)\n",
    "            for j in range(len(accuracy)):\n",
    "                layers_accuracy[j] += accuracy[j]\n",
    "            # print(loss)\n",
    "            # print(accuracy)\n",
    "            # total_loss += loss\n",
    "            # losses.append(float(loss))\n",
    "            total_sample += labels.size(0)\n",
    "\n",
    "            # Backward and optimize\n",
    "            for j in range(len(loss)):\n",
    "                if j + 1 == len(loss):\n",
    "                    loss[j].backward()\n",
    "                else:\n",
    "                    loss[j].backward(retain_graph = True)\n",
    "            optimizer.step()\n",
    "            del images, labels, outputs\n",
    "            torch.mps.empty_cache() if torch.backends.mps.is_available() else torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "\n",
    "            if (i + 1) % 3 == 0 or i + 1 == total_step + 1:\n",
    "                bar_step.set_postfix({\n",
    "                            'avg_loss': float(total_loss) / (i + 1),\n",
    "                            'avg_accuracy': (sum(layers_accuracy)/3) / (i + 1),\n",
    "                            # 'max_abs_gradient': np.max(abs(model.weight.grad))\n",
    "                        })\n",
    "                cur_n_batch = i % 3 + 1\n",
    "                bar_step.update(cur_n_batch)\n",
    "\n",
    "    # print ('Epoch [{}/{}], Loss: {:.4f}' .format(epoch+1, num_epochs, round(np.mean(losses))))\n",
    "    for p in range(len(layers_accuracy)):\n",
    "        accuracy1 = 100 * layers_accuracy[p] / total_sample\n",
    "        print(f'Epoch {epoch+1}: Accuracy of Exit layer {p + 1} = {accuracy1:.2f}%')\n",
    "        \n",
    "    # model.eval()\n",
    "                \n",
    "        # Validation\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in valid_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs[-1].data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            del images, labels, outputs\n",
    "        \n",
    "        print('Accuracy of the network on the {} validation images: {} %'.format(5000, 100 * correct / total)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs[-1].data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        del images, labels, outputs\n",
    "\n",
    "    print('Accuracy of the network on the {} test images: {} %'.format(10000, 100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
